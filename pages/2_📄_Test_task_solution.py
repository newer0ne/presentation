import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from io import StringIO

st.set_page_config(
    page_title="Test task in work", page_icon="üìä", layout="wide", initial_sidebar_state="expanded"
)

st.write(
    """
# üìä ADS analyzer
–û—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ä–µ–∫–ª–∞–º–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏.
"""
)

upcol1, upcol2, upcol3 = st.columns(3)

with upcol1:
    uploaded_ads = st.file_uploader("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∫–ª–∞–º–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ .CSV", type=".csv")

with upcol2:
    uploaded_leads = st.file_uploader("–ó–∞–≥—Ä—É–∑–∫–∞ –ª–∏–¥–æ–≤ .CSV", type=".csv")

with upcol3:
    uploaded_purchases = st.file_uploader("–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–¥–∞–∂ .CSV", type=".csv")

use_example = st.checkbox(
    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª —Å –ø—Ä–∏–º–µ—Ä–æ–º", False, help="–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –ø—Ä–∏–º–µ—Ä–æ–º —Ä–µ–∫–ª–∞–º—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"
)

if use_example:
    uploaded_ads = "ads.csv"
    uploaded_leads = "leads.csv"
    uploaded_purchases = "purchases.csv"

if uploaded_ads:
    ads = pd.read_csv(uploaded_ads)
if uploaded_leads:
    leads = pd.read_csv(uploaded_leads)
if uploaded_purchases:
    purchases = pd.read_csv(uploaded_purchases)

if uploaded_ads is not None and uploaded_leads is not None and uploaded_purchases is not None:
    
    ads_tab, leads_tab, purchases_tab = st.tabs(['ads', 'leads', 'purchases'])

    with ads_tab:
        
        st.markdown('#### –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º ads')
        st.dataframe(ads)

        ads['d_utm_term'] = ads['d_utm_term'].fillna('-')
        ads['created_at'] = pd.to_datetime(ads['created_at'], format = '%Y-%m-%d', errors = 'ignore')
        
        st.markdown('#### –†–µ–∫–ª–∞–º: –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏, –ø—Ä–∏–≤–æ–¥–∏–º –¥–∞—Ç—ã')
        st.dataframe(ads)
    
    with leads_tab:

        st.markdown('#### –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º leads')
        st.dataframe(leads)
        
        leads.fillna({'d_lead_utm_source': '-',
            'd_lead_utm_medium': '-',
            'd_lead_utm_campaign': '-',
            'd_lead_utm_content': '-',
            'd_lead_utm_term': '-'}, inplace=True)
        
        leads.rename(columns = {'d_lead_utm_source': 'd_utm_source',
            'd_lead_utm_medium': 'd_utm_medium',
            'd_lead_utm_campaign': 'd_utm_campaign',
            'd_lead_utm_content': 'd_utm_content',
            'd_lead_utm_term': 'd_utm_term',
            'lead_created_at': 'created_at'}, inplace=True)
        
        leads['created_at'] = pd.to_datetime(leads['created_at'], format = '%Y-%m-%d', errors = 'ignore')

        st.markdown('#### –õ–∏–¥—ã: –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏, –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º, –ø—Ä–∏–≤–æ–¥–∏–º –¥–∞—Ç—ã')
        st.dataframe(leads)
    
    with purchases_tab:
        
        st.markdown('### –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º purchases')
        st.dataframe(purchases)

        purchases['purchase_created_at'] = pd.to_datetime(purchases['purchase_created_at'], format = '%Y-%m-%d', errors = 'ignore')
        purchases.dropna(axis=0, subset=['m_purchase_amount'], inplace=True)
        
        st.markdown('#### –ü—Ä–æ–¥–∞–∂–∏: —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ –ø—Ä–æ–¥–∞–∂–∏, –ø—Ä–∏–≤–æ–¥–∏–º –¥–∞—Ç—ã')
        st.dataframe(purchases)

    st.markdown("""
        –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª–∏–¥—ã –∏ –ø—Ä–æ–¥–∞–∂–∏:
            - –õ–∏–¥—É –∑–∞—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø—Ä–æ–¥–∞–∂–∞ –Ω–µ –ø–æ–∑–¥–Ω–µ–µ 15 –¥–Ω–µ–π
            - purchase_id –Ω–µ –º–æ–∂–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è
            - –ß–∞—Å—Ç—å –ª–∏–¥–æ–≤ –º–æ–∂–µ—Ç –ø–æ—Ç–µ—Ä—è—Ç—å—Å—è, –∫–æ–≥–¥–∞ –º—ã –¥–µ–ª–∞–µ–º drop_duplicates
            """)

    compose = leads[['client_id', 'created_at', 'lead_id']].merge(purchases, 'left', 'client_id')
    st.dataframe(compose)

    delta = timedelta(days=15)

    compose = compose.query('purchase_created_at - created_at <= @delta and created_at <= purchase_created_at')

    compose = compose.sort_values('created_at', ascending=False)\
        .drop_duplicates('purchase_id', keep='first')

    agg_func = {'m_purchase_count': ('purchase_id', 'count'),
        'm_purchase_amount': ('m_purchase_amount', 'sum')}

    compose = compose.groupby('lead_id').agg(**agg_func).reset_index()

    leads_full = leads.merge(compose, 'left', 'lead_id')
    st.dataframe(leads_full)

    compose.lead_id.nunique(), leads_full.lead_id.nunique()

    st.markdown('#### –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∫–ª–∞–º—É –∏ –ª–∏–¥–æ–≤ –ø–æ —Ç–µ–º –ø–æ–ª—è–º, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –¥–∂–æ–π–Ω–∞')

    columns_to_groupby = ['created_at',
                      'd_utm_source',
                      'd_utm_medium',
                      'd_utm_campaign',
                      'd_utm_content',
                      'd_utm_term'] 
    agg_func = {'m_clicks': ('m_clicks', 'sum'),
           'm_cost': ('m_cost', 'sum')}

    ads = ads.groupby(columns_to_groupby).agg(**agg_func).reset_index()
    ads.d_utm_campaign = ads.d_utm_campaign.astype('str')
    ads.d_utm_content = ads.d_utm_content.astype('str')

    agg_func = {'m_leads_count': ('lead_id', 'nunique'),
            'm_purchase_count': ('m_purchase_count', 'sum'),
           'm_purchase_amount': ('m_purchase_amount', 'sum')}

    leads_full = leads_full.groupby(columns_to_groupby).agg(**agg_func).reset_index()

    st.dataframe(leads_full)

    st.markdown('#### –î–∂–æ–π–Ω —Ä–µ–∫–ª–∞–º—ã –∏ –ª–∏–¥–æ–≤, —Å—á–∏—Ç–∞–µ–º –¥–æ–ø –º–µ—Ç—Ä–∏–∫–∏')

    result = ads.merge(leads_full, 'outer', columns_to_groupby)
    result.fillna(0, inplace=True)

    result['cpl'] = np.where(result['m_leads_count'] != 0,
        result['m_cost'] / result['m_leads_count'],
        0)

    result['roas'] = np.where(result['m_cost'] != 0,
        result['m_purchase_amount'] / result['m_cost'],
        0)

    result[result['cpl'] > 0]
